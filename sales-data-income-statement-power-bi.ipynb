{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Step 1. Import dependencies & download the dataset\nWe use `kagglehub` to pull the dataset *Sales Data for Economic Data Analysis* directly into our environment.\n","metadata":{}},{"cell_type":"code","source":"import os,glob,re\nimport pandas as pd\nimport numpy as np\n\nimport kagglehub\n\n# Download latest version\npath = kagglehub.dataset_download(\"abhishekrp1517/sales-data-for-economic-data-analysis\")\n\nprint(\"Path to dataset files:\", path)\n\nall_files=[]\nfor ext in(\"*.csv\",\"*.xlsx\",\"*.xls\",\"*.parquet\"):\n    all_files.extend(glob.glob(os.path.join(path,ext)))\n\nprint(\"files discovered:\",all_files)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T19:22:55.416240Z","iopub.execute_input":"2025-09-22T19:22:55.416548Z","iopub.status.idle":"2025-09-22T19:23:02.361369Z","shell.execute_reply.started":"2025-09-22T19:22:55.416523Z","shell.execute_reply":"2025-09-22T19:23:02.360433Z"}},"outputs":[{"name":"stdout","text":"Path to dataset files: /kaggle/input/sales-data-for-economic-data-analysis\nfiles discovered: ['/kaggle/input/sales-data-for-economic-data-analysis/salesforcourse-4fe2kehu.csv', '/kaggle/input/sales-data-for-economic-data-analysis/salesforcourse-4fe2kehu.xlsx']\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"### Step 2. Load the dataset\nSelect the best available file (CSV preferred). Then preview its shape and first rows.\n","metadata":{}},{"cell_type":"code","source":"import os, zipfile\nfrom pathlib import Path\n\nroot = path  # from kagglehub download\n\ndef list_all_files(start_dir):\n    out = []\n    for r, _, files in os.walk(start_dir):\n        for f in files:\n            out.append(os.path.join(r, f))\n    return out\n\nfiles = list_all_files(root)\nprint(\"Found files initially:\")\nfor f in files:\n    print(\" -\", f)\n\n# Unzip if .zip files are found\nfor f in files:\n    if f.lower().endswith(\".zip\"):\n        print(\"Unzipping:\", f)\n        with zipfile.ZipFile(f) as z:\n            z.extractall(Path(f).parent)\n\n# Re-list after unzip\nfiles = list_all_files(root)\nprint(\"\\nFiles after unzip:\")\nfor f in files:\n    print(\" -\", f)\nfrom os.path import getsize\n\nCAND_EXTS = (\".csv\", \".csv.gz\", \".tsv\", \".xlsx\", \".xls\", \".parquet\", \".json\", \".txt\")\n\ncandidates = [f for f in files if f.lower().endswith(CAND_EXTS)]\nif not candidates:\n    raise FileNotFoundError(\"No candidate data files found (csv/xlsx/parquet/tsv/json/txt).\")\n\n# Sort by extension priority and file size\next_priority = {\".csv\":1, \".csv.gz\":1, \".tsv\":2, \".xlsx\":3, \".xls\":3, \".parquet\":4, \".json\":5, \".txt\":6}\n\ndef file_score(p):\n    p_low = p.lower()\n    score = min([ext_priority[e] for e in ext_priority if p_low.endswith(e)])\n    return (score, -getsize(p))\n\ncandidates_sorted = sorted(candidates, key=file_score)\ndata_file = candidates_sorted[0]\nprint(\"Selected file:\", data_file)\n\n# ---- Step 2c (fixed): robust reader without the low_memory+python conflict ----\nimport pandas as pd\n\ndef read_any(path, nrows=None):\n    p = path.lower()\n\n    # CSV / TSV / TXT\n    if p.endswith((\".csv\", \".csv.gz\", \".tsv\", \".txt\")):\n        # If it's clearly TSV, set sep=\"\\t\" and use default engine (\"c\")\n        if p.endswith(\".tsv\"):\n            return pd.read_csv(path, sep=\"\\t\", nrows=nrows)  # default engine OK\n        # Otherwise, try automatic separator inference using the python engine,\n        # but DO NOT pass low_memory (that triggers your error).\n        try:\n            return pd.read_csv(path, sep=None, engine=\"python\", nrows=nrows)\n        except Exception as e:\n            print(\"[read_any] Fallback: trying default engine with comma sep due to:\", e)\n            return pd.read_csv(path, sep=\",\", nrows=nrows)\n\n    # Excel\n    if p.endswith((\".xlsx\", \".xls\")):\n        return pd.read_excel(path)\n\n    # Parquet\n    if p.endswith(\".parquet\"):\n        return pd.read_parquet(path)\n\n    # JSON (supports JSON lines or standard)\n    if p.endswith(\".json\"):\n        try:\n            return pd.read_json(path, lines=True)\n        except ValueError:\n            return pd.read_json(path)\n\n    raise ValueError(f\"Unsupported file type: {path}\")\n\n# Use the loader\nprint(\"Selected file:\", data_file)\ndf_raw = read_any(data_file)\nprint(\"Raw shape:\", df_raw.shape)\ndf_raw.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T20:19:17.143962Z","iopub.execute_input":"2025-09-22T20:19:17.144254Z","iopub.status.idle":"2025-09-22T20:19:17.572204Z","shell.execute_reply.started":"2025-09-22T20:19:17.144232Z","shell.execute_reply":"2025-09-22T20:19:17.571589Z"}},"outputs":[{"name":"stdout","text":"Found files initially:\n - /kaggle/input/sales-data-for-economic-data-analysis/salesforcourse-4fe2kehu.csv\n - /kaggle/input/sales-data-for-economic-data-analysis/salesforcourse-4fe2kehu.xlsx\n\nFiles after unzip:\n - /kaggle/input/sales-data-for-economic-data-analysis/salesforcourse-4fe2kehu.csv\n - /kaggle/input/sales-data-for-economic-data-analysis/salesforcourse-4fe2kehu.xlsx\nSelected file: /kaggle/input/sales-data-for-economic-data-analysis/salesforcourse-4fe2kehu.csv\nSelected file: /kaggle/input/sales-data-for-economic-data-analysis/salesforcourse-4fe2kehu.csv\nRaw shape: (34867, 16)\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n  has_large_values = (abs_vals > 1e6).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"   index       Date    Year     Month  Customer Age Customer Gender  \\\n0      0  2/19/2016  2016.0  February          29.0               F   \n1      1  2/20/2016  2016.0  February          29.0               F   \n2      2  2/27/2016  2016.0  February          29.0               F   \n3      3  3/12/2016  2016.0     March          29.0               F   \n4      4  3/12/2016  2016.0     March          29.0               F   \n\n         Country       State Product Category     Sub Category  Quantity  \\\n0  United States  Washington      Accessories  Tires and Tubes       1.0   \n1  United States  Washington         Clothing           Gloves       2.0   \n2  United States  Washington      Accessories  Tires and Tubes       3.0   \n3  United States  Washington      Accessories  Tires and Tubes       2.0   \n4  United States  Washington      Accessories  Tires and Tubes       3.0   \n\n   Unit Cost  Unit Price   Cost  Revenue  Column1  \n0      80.00  109.000000   80.0    109.0      NaN  \n1      24.50   28.500000   49.0     57.0      NaN  \n2       3.67    5.000000   11.0     15.0      NaN  \n3      87.50  116.500000  175.0    233.0      NaN  \n4      35.00   41.666667  105.0    125.0      NaN  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>Date</th>\n      <th>Year</th>\n      <th>Month</th>\n      <th>Customer Age</th>\n      <th>Customer Gender</th>\n      <th>Country</th>\n      <th>State</th>\n      <th>Product Category</th>\n      <th>Sub Category</th>\n      <th>Quantity</th>\n      <th>Unit Cost</th>\n      <th>Unit Price</th>\n      <th>Cost</th>\n      <th>Revenue</th>\n      <th>Column1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>2/19/2016</td>\n      <td>2016.0</td>\n      <td>February</td>\n      <td>29.0</td>\n      <td>F</td>\n      <td>United States</td>\n      <td>Washington</td>\n      <td>Accessories</td>\n      <td>Tires and Tubes</td>\n      <td>1.0</td>\n      <td>80.00</td>\n      <td>109.000000</td>\n      <td>80.0</td>\n      <td>109.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2/20/2016</td>\n      <td>2016.0</td>\n      <td>February</td>\n      <td>29.0</td>\n      <td>F</td>\n      <td>United States</td>\n      <td>Washington</td>\n      <td>Clothing</td>\n      <td>Gloves</td>\n      <td>2.0</td>\n      <td>24.50</td>\n      <td>28.500000</td>\n      <td>49.0</td>\n      <td>57.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2/27/2016</td>\n      <td>2016.0</td>\n      <td>February</td>\n      <td>29.0</td>\n      <td>F</td>\n      <td>United States</td>\n      <td>Washington</td>\n      <td>Accessories</td>\n      <td>Tires and Tubes</td>\n      <td>3.0</td>\n      <td>3.67</td>\n      <td>5.000000</td>\n      <td>11.0</td>\n      <td>15.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>3/12/2016</td>\n      <td>2016.0</td>\n      <td>March</td>\n      <td>29.0</td>\n      <td>F</td>\n      <td>United States</td>\n      <td>Washington</td>\n      <td>Accessories</td>\n      <td>Tires and Tubes</td>\n      <td>2.0</td>\n      <td>87.50</td>\n      <td>116.500000</td>\n      <td>175.0</td>\n      <td>233.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>3/12/2016</td>\n      <td>2016.0</td>\n      <td>March</td>\n      <td>29.0</td>\n      <td>F</td>\n      <td>United States</td>\n      <td>Washington</td>\n      <td>Accessories</td>\n      <td>Tires and Tubes</td>\n      <td>3.0</td>\n      <td>35.00</td>\n      <td>41.666667</td>\n      <td>105.0</td>\n      <td>125.0</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":7},{"cell_type":"markdown","source":"### Step 3. Normalize column names\nConvert all column names to lowercase, snake_case, and remove special characters for consistency.\n","metadata":{}},{"cell_type":"code","source":"def normalize_cols(cols):\n    out=[]\n    for c in cols:\n        c2= c.strip().lower()\n        c2= re.sub(r\"[\\s/]+\",\"_\",c2)\n        c2= re.sub(r\"[^0-9a-zA-Z_]\",\"\",c2)\n        out.append(c2)\n    return out\ndf_raw.columns = normalize_cols(df_raw.columns)\ndf_raw.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T20:31:12.015615Z","iopub.execute_input":"2025-09-22T20:31:12.016063Z","iopub.status.idle":"2025-09-22T20:31:12.036390Z","shell.execute_reply.started":"2025-09-22T20:31:12.015975Z","shell.execute_reply":"2025-09-22T20:31:12.035595Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n  has_large_values = (abs_vals > 1e6).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"   index       date    year     month  customer_age customer_gender  \\\n0      0  2/19/2016  2016.0  February          29.0               F   \n1      1  2/20/2016  2016.0  February          29.0               F   \n2      2  2/27/2016  2016.0  February          29.0               F   \n3      3  3/12/2016  2016.0     March          29.0               F   \n4      4  3/12/2016  2016.0     March          29.0               F   \n\n         country       state product_category     sub_category  quantity  \\\n0  United States  Washington      Accessories  Tires and Tubes       1.0   \n1  United States  Washington         Clothing           Gloves       2.0   \n2  United States  Washington      Accessories  Tires and Tubes       3.0   \n3  United States  Washington      Accessories  Tires and Tubes       2.0   \n4  United States  Washington      Accessories  Tires and Tubes       3.0   \n\n   unit_cost  unit_price   cost  revenue  column1  \n0      80.00  109.000000   80.0    109.0      NaN  \n1      24.50   28.500000   49.0     57.0      NaN  \n2       3.67    5.000000   11.0     15.0      NaN  \n3      87.50  116.500000  175.0    233.0      NaN  \n4      35.00   41.666667  105.0    125.0      NaN  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>date</th>\n      <th>year</th>\n      <th>month</th>\n      <th>customer_age</th>\n      <th>customer_gender</th>\n      <th>country</th>\n      <th>state</th>\n      <th>product_category</th>\n      <th>sub_category</th>\n      <th>quantity</th>\n      <th>unit_cost</th>\n      <th>unit_price</th>\n      <th>cost</th>\n      <th>revenue</th>\n      <th>column1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>2/19/2016</td>\n      <td>2016.0</td>\n      <td>February</td>\n      <td>29.0</td>\n      <td>F</td>\n      <td>United States</td>\n      <td>Washington</td>\n      <td>Accessories</td>\n      <td>Tires and Tubes</td>\n      <td>1.0</td>\n      <td>80.00</td>\n      <td>109.000000</td>\n      <td>80.0</td>\n      <td>109.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2/20/2016</td>\n      <td>2016.0</td>\n      <td>February</td>\n      <td>29.0</td>\n      <td>F</td>\n      <td>United States</td>\n      <td>Washington</td>\n      <td>Clothing</td>\n      <td>Gloves</td>\n      <td>2.0</td>\n      <td>24.50</td>\n      <td>28.500000</td>\n      <td>49.0</td>\n      <td>57.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2/27/2016</td>\n      <td>2016.0</td>\n      <td>February</td>\n      <td>29.0</td>\n      <td>F</td>\n      <td>United States</td>\n      <td>Washington</td>\n      <td>Accessories</td>\n      <td>Tires and Tubes</td>\n      <td>3.0</td>\n      <td>3.67</td>\n      <td>5.000000</td>\n      <td>11.0</td>\n      <td>15.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>3/12/2016</td>\n      <td>2016.0</td>\n      <td>March</td>\n      <td>29.0</td>\n      <td>F</td>\n      <td>United States</td>\n      <td>Washington</td>\n      <td>Accessories</td>\n      <td>Tires and Tubes</td>\n      <td>2.0</td>\n      <td>87.50</td>\n      <td>116.500000</td>\n      <td>175.0</td>\n      <td>233.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>3/12/2016</td>\n      <td>2016.0</td>\n      <td>March</td>\n      <td>29.0</td>\n      <td>F</td>\n      <td>United States</td>\n      <td>Washington</td>\n      <td>Accessories</td>\n      <td>Tires and Tubes</td>\n      <td>3.0</td>\n      <td>35.00</td>\n      <td>41.666667</td>\n      <td>105.0</td>\n      <td>125.0</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":10},{"cell_type":"markdown","source":"### Step 4. Identify key fields\nWe search for potential columns representing:\n- **Revenue (sales)**  \n- **Cost (COGS)**  \n- **Quantity, price** (if totals are not given)  \n- **Date**  \n","metadata":{}},{"cell_type":"code","source":"def find_one(patterns):\n    for p in patterns:\n        for c in df_raw.columns:\n            if re.search(p,c,flags=re.I):\n                return c\n        return none\n\ndate_col = find_one([r\"date\"])\nqty_col  = find_one([r\"qty|quantity\"])\nrev_col  = find_one([r\"revenue|sales|amount\"])\ncost_col = find_one([r\"cost|cogs|expense\"])\n\nprint(\"date column\",date_col)\nprint(\"Quantity\",qty_col)\nprint(\"Revenue\",rev_col)\nprint(\"Cost\",cost_col)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T20:38:22.764310Z","iopub.execute_input":"2025-09-22T20:38:22.764589Z","iopub.status.idle":"2025-09-22T20:38:22.770548Z","shell.execute_reply.started":"2025-09-22T20:38:22.764569Z","shell.execute_reply":"2025-09-22T20:38:22.769894Z"}},"outputs":[{"name":"stdout","text":"date column date\nQuantity quantity\nRevenue revenue\nCost unit_cost\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"### Step 5. Clean and convert data types\n- Parse dates properly  \n- Convert numeric fields to floats  \n- Handle missing values  \n","metadata":{}},{"cell_type":"code","source":"df= df_raw.copy()\n\nif date_col:\n    df[date_col] = pd.to_datetime(df[date_col],errors=\"coerce\")\n\nfor col in [rev_col, cost_col, qty_col]:\n    if col and col in df.columns:\n        df[col]= pd.to_numeric(df[col],errors=\"coerce\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T20:42:37.602176Z","iopub.execute_input":"2025-09-22T20:42:37.602708Z","iopub.status.idle":"2025-09-22T20:42:37.623718Z","shell.execute_reply.started":"2025-09-22T20:42:37.602686Z","shell.execute_reply":"2025-09-22T20:42:37.622844Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"### Step 6. Derive P&L metrics\nWe standardize the fields to:\n- `Revenue`  \n- `Cost`  \n- `Profit = Revenue - Cost`  \n- `Profit_Margin = Profit / Revenue`  \n","metadata":{}},{"cell_type":"code","source":"df[\"Revenue\"]=df[rev_col]\ndf[\"Cost\"]   =df[cost_col]\ndf[\"Profit\"] =df[\"Revenue\"] - df[\"Cost\"]\ndf[\"Profit_Margin\"]= df[\"Profit\"] / df[\"Revenue\"]\n\ndf[[\"Revenue\",\"Cost\",\"Profit\",\"Profit_Margin\"]].head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T20:47:00.074358Z","iopub.execute_input":"2025-09-22T20:47:00.074663Z","iopub.status.idle":"2025-09-22T20:47:00.159934Z","shell.execute_reply.started":"2025-09-22T20:47:00.074641Z","shell.execute_reply":"2025-09-22T20:47:00.159274Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"   Revenue   Cost  Profit  Profit_Margin\n0    109.0  80.00   29.00       0.266055\n1     57.0  24.50   32.50       0.570175\n2     15.0   3.67   11.33       0.755333\n3    233.0  87.50  145.50       0.624464\n4    125.0  35.00   90.00       0.720000","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Revenue</th>\n      <th>Cost</th>\n      <th>Profit</th>\n      <th>Profit_Margin</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>109.0</td>\n      <td>80.00</td>\n      <td>29.00</td>\n      <td>0.266055</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>57.0</td>\n      <td>24.50</td>\n      <td>32.50</td>\n      <td>0.570175</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>15.0</td>\n      <td>3.67</td>\n      <td>11.33</td>\n      <td>0.755333</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>233.0</td>\n      <td>87.50</td>\n      <td>145.50</td>\n      <td>0.624464</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>125.0</td>\n      <td>35.00</td>\n      <td>90.00</td>\n      <td>0.720000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":14},{"cell_type":"markdown","source":"### Step 7. Add date intelligence\nWe create Year, Month, and Quarter columns to allow time-based slicing in Power BI.\n","metadata":{}},{"cell_type":"code","source":"df[\"Year\"] = df[date_col].dt.year\ndf[\"Month\"]= df[date_col].dt.month\ndf[\"Quarter\"]  = \"Q\" + df[date_col].dt.quarter.astype(str)\n\ndf[[\"Year\",\"Month\",\"Quarter\"]].head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T20:50:53.802224Z","iopub.execute_input":"2025-09-22T20:50:53.802499Z","iopub.status.idle":"2025-09-22T20:50:53.840566Z","shell.execute_reply.started":"2025-09-22T20:50:53.802481Z","shell.execute_reply":"2025-09-22T20:50:53.839803Z"}},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"     Year  Month Quarter\n0  2016.0    2.0    Q1.0\n1  2016.0    2.0    Q1.0\n2  2016.0    2.0    Q1.0\n3  2016.0    3.0    Q1.0\n4  2016.0    3.0    Q1.0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Year</th>\n      <th>Month</th>\n      <th>Quarter</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2016.0</td>\n      <td>2.0</td>\n      <td>Q1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2016.0</td>\n      <td>2.0</td>\n      <td>Q1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2016.0</td>\n      <td>2.0</td>\n      <td>Q1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2016.0</td>\n      <td>3.0</td>\n      <td>Q1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2016.0</td>\n      <td>3.0</td>\n      <td>Q1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":15},{"cell_type":"markdown","source":"### Step 8. Export cleaned dataset\nWe now save the cleaned dataset as `fact_sales.csv` for loading into Power BI.\n","metadata":{}},{"cell_type":"code","source":"out_path = \"/kaggle/working/fact_sales.csv\"\ndf.to_csv(out_path, index=False)\nprint(\"saved cleaned dataset to\", out_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T20:52:32.389454Z","iopub.execute_input":"2025-09-22T20:52:32.389727Z","iopub.status.idle":"2025-09-22T20:52:32.936903Z","shell.execute_reply.started":"2025-09-22T20:52:32.389709Z","shell.execute_reply":"2025-09-22T20:52:32.936253Z"}},"outputs":[{"name":"stdout","text":"saved cleaned dataset to /kaggle/working/fact_sales.csv\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}